from faster_whisper import WhisperModel
from pydub import AudioSegment
from ..constants import ASR_MODEL_PATH
import opencc  # ðŸ‘ˆ æ–°å¢ž
import os


if not os.path.exists(ASR_MODEL_PATH):
    raise FileNotFoundError(f"âŒ æ¨¡åž‹ç›®å½•ä¸å­˜åœ¨ï¼š{ASR_MODEL_PATH}")

model = WhisperModel(str(ASR_MODEL_PATH), device="cuda", compute_type="float16")

converter = opencc.OpenCC('t2s')  # ðŸ‘ˆ ç¹ä½“è½¬ç®€ä½“

def recognize_audio(raw_path: str) -> str:
    fixed_path = raw_path.replace("raw_", "fixed_")

    try:
        sound = AudioSegment.from_file(raw_path)
        duration_ms = len(sound)
        print(f"[ðŸŽ§] éŸ³é¢‘æ—¶é•¿ï¼š{duration_ms}ms")

        if duration_ms < 1000:
            print("â—éŸ³é¢‘è¿‡çŸ­ï¼Œè·³è¿‡è¯†åˆ«")
            return ""

        sound = sound.set_channels(1).set_frame_rate(16000).set_sample_width(2)
        sound.export(fixed_path, format="wav")
        print("[ðŸŽ§] éŸ³é¢‘å·²è½¬æ¢ä¸º 16kHz å•å£°é“ PCM")

        if os.path.getsize(fixed_path) < 2048:
            print("â—éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ— æ•ˆ")
            return ""

        segments, info = model.transcribe(fixed_path, language="zh", beam_size=5, vad_filter=True)
        result = "".join([seg.text for seg in segments])

        # ðŸ‘‡ åŠ ä¸Šç¹è½¬ç®€
        result = converter.convert(result)

        print("[âœ…] è¯†åˆ«ç»“æžœï¼ˆç®€ä½“ï¼‰ï¼š", result)
        os.remove(fixed_path)
        return result

    except Exception as e:
        print("[âŒ è¯†åˆ«å¤±è´¥]", str(e))
        raise e
